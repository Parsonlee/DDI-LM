{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import sqlite3\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
        "pd.set_option(\"display.max_rows\", 20)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "data_path = \"./data\"\n",
        "# data_path = \"/kaggle/input/ddidatasets\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "small dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conn = sqlite3.connect(f\"{data_path}/event.db\")\n",
        "# df_drug = pd.read_sql(\"select * from drug;\", conn)\n",
        "# extraction = pd.read_sql(\"select * from extraction;\", conn)\n",
        "# mechanism = extraction[\"mechanism\"]\n",
        "# action = extraction[\"action\"]\n",
        "# drugA = extraction[\"drugA\"]\n",
        "# drugB = extraction[\"drugB\"]\n",
        "\n",
        "# extraction[\"label_text\"] = extraction.mechanism + \" \" + extraction.action\n",
        "\n",
        "# # extraction[\"label_text\"] = LabelEncoder().fit_transform(extraction.mechanism)\n",
        "# extraction[\"label_text\"] = extraction[\"label_text\"].apply(str.lower)\n",
        "# extraction = extraction.drop(['index'], axis=1)\n",
        "# df_drug = df_drug.drop(['id', 'index'], axis=1)\n",
        "# df_drug = df_drug.set_index('name')\n",
        "\n",
        "# ## check number of classes\n",
        "# # extraction['label_text'].value_counts()\n",
        "# ## check number of drugs\n",
        "# # df_drug.index\n",
        "\n",
        "# display(df_drug.head(2))\n",
        "# display(extraction.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "big dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "events = pd.read_csv(f\"{data_path}/events.csv\", index_col=0)\n",
        "df_drugs = pd.read_csv(f\"{data_path}/drugs.csv\", index_col=0)\n",
        "\n",
        "display(events.head(2))\n",
        "display(df_drugs.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_metrics(pred_probs, labels):\n",
        "    pred_probs = np.concatenate(pred_probs, axis=0)\n",
        "    labels = np.concatenate(labels, axis=0)\n",
        "    print(pred_probs.shape, labels.shape)\n",
        "\n",
        "    # 获得预测的类别\n",
        "    predicted_labels = pred_probs.argmax(axis=1)\n",
        "\n",
        "    # 计算accuracy\n",
        "    accuracy = accuracy_score(labels, predicted_labels)\n",
        "\n",
        "    # 计算precision、recall、F1-score\n",
        "    precision = precision_score(labels, predicted_labels, average=\"micro\")\n",
        "    recall = recall_score(labels, predicted_labels, average=\"micro\")\n",
        "    f1 = f1_score(labels, predicted_labels, average=\"micro\")\n",
        "\n",
        "    # 计算AUC和AUPR\n",
        "    auc_score = roc_auc_score(\n",
        "        labels, pred_probs, average=\"macro\", multi_class=\"ovr\"\n",
        "    )\n",
        "    aupr_score = average_precision_score(labels, pred_probs, average=\"micro\")\n",
        "\n",
        "    # return a dict\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"auc_score\": auc_score,\n",
        "        \"aupr_score\": aupr_score,\n",
        "    }\n",
        "    # return accuracy, precision, recall, f1, auc_score, aupr_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_path = './original/models/'\n",
        "model_path = '/kaggle/input/ddi-lm-models/original/models/'\n",
        "models = [f'{model_path}{model}' for model in os.listdir(model_path) if os.path.isdir(f'{model_path}{model}')]\n",
        "\n",
        "current_model = models[0]\n",
        "tokenizer = AutoTokenizer.from_pretrained(current_model)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(current_model)\n",
        "print(f'model: {current_model} Loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DDI_Dataset(Dataset):\n",
        "    def __init__(self, ev_df, drug_df, tokenizer, max_len=256):\n",
        "        self.events = ev_df\n",
        "        self.drugs = drug_df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.events.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        d_a, d_b, labels = self.events.iloc[index, [2, 3, -1]]\n",
        "        # d_a_seq = d_a + \",\" + ','.join(self.drugs.loc[d_a].values)\n",
        "        # d_b_seq = d_b + \",\" + ','.join(self.drugs.loc[d_b].values)\n",
        "        \n",
        "        # use different modal\n",
        "        # d_a_seq = d_a + f\", the drug {d_a}'s chemical form is: \" + self.drugs.loc[d_a].target\n",
        "        # d_b_seq = d_b + f\", the drug {d_b}'s chemical form is: \" + self.drugs.loc[d_b].target\n",
        "        # text = f'{d_a_seq + \" \" + self.tokenizer.sep_token + \" \" + d_b_seq}'\n",
        "\n",
        "        # use prompt\n",
        "        text = f\"The drug {d_a} interacts with the drug {d_b}. \\\n",
        "            The drug {d_a}'s information is: {','.join(self.drugs.loc[d_a].values)}. \\\n",
        "            The drug {d_b}'s information is: {','.join(self.drugs.loc[d_b].values)}.\"\n",
        "        \n",
        "        # print(text)\n",
        "\n",
        "        encode_dict = self.tokenizer.encode_plus(\n",
        "            text=text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        ids = encode_dict[\"input_ids\"].squeeze(0)\n",
        "        masks = encode_dict[\"attention_mask\"].squeeze(0)\n",
        "        \n",
        "        return {\"ids\": ids, \"masks\": masks, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model, loader):\n",
        "    total_probs = []\n",
        "    total_labels = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for step, b in tqdm(enumerate(loader), total=len(loader), desc=\"Test\"):\n",
        "            b = {k: v.to(device) for k, v in b.items()}\n",
        "            ids, masks, labels = b[\"ids\"], b[\"masks\"], b[\"labels\"]\n",
        "\n",
        "            outputs = model(ids, masks)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "            total_probs.append(probs)\n",
        "            total_labels.append(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "    total_probs = np.concatenate(total_probs, axis=0)\n",
        "    total_labels = np.concatenate(total_labels, axis=0)\n",
        "    print(f'predict: {total_probs.shape}, {total_labels.shape}')\n",
        "    return total_probs, total_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_val(events, df_drugs, tokenizer, model):\n",
        "    skf = StratifiedKFold(n_splits=5)\n",
        "    total_pred_scores = []\n",
        "    total_labels = []\n",
        "    cv_results = []\n",
        "\n",
        "    for train_index, test_index in skf.split(np.zeros(len(events)), events['label']):\n",
        "\n",
        "        # train_dataset = DDI_Dataset(events.iloc[train_index], df_drugs, tokenizer, max_len=256)\n",
        "        test_dataset = DDI_Dataset(events.iloc[test_index], df_drugs, tokenizer, max_len=256)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "        pred_scores, labels = predict(model, test_loader)\n",
        "\n",
        "        total_pred_scores.append(pred_scores)\n",
        "        total_labels.append(labels)\n",
        "        total_pred_scores = np.concatenate(total_pred_scores, axis=0)\n",
        "        total_labels = np.concatenate(total_labels, axis=0)\n",
        "        \n",
        "        print(f'evaluate: {total_pred_scores.shape}, {total_labels.shape}')\n",
        "        results = evaluate_metrics(total_pred_scores, total_labels)\n",
        "        cv_results.append(results)\n",
        "        print(\"results: \", results)\n",
        "\n",
        "    return cv_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val(events, df_drugs, tokenizer, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mQjoB8u2eKe7",
        "9awh5pBeeKe-",
        "bdTuoeiLeKe_",
        "cKCsIJNOeKe_",
        "CUzcDdUdeKe_",
        "5ZkoFgtdeKfA",
        "n6NRi2VpeKfC",
        "v7PXBEHQeKfC",
        "WJyMf0AyDzFr",
        "TIQrw1AKCdaF",
        "OCnUrFpCCdaG",
        "-CThUUkRCdaI",
        "uFzXjk4mDzFt",
        "4kuqahhxDzFt",
        "3Pp2A2N3DzFu",
        "LVZv8Mw1DzFu",
        "11S2Fs7iDzFu",
        "UsF7VqwZeKfD",
        "m425KHhNeKfD",
        "9rggZUTNeKfD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "work",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
