{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008378,"end_time":"2022-10-14T16:18:34.771499","exception":false,"start_time":"2022-10-14T16:18:34.763121","status":"completed"},"tags":[]},"source":["# Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:22:56.346521Z","iopub.status.busy":"2023-07-10T06:22:56.346187Z","iopub.status.idle":"2023-07-10T06:23:01.462550Z","shell.execute_reply":"2023-07-10T06:23:01.461562Z","shell.execute_reply.started":"2023-07-10T06:22:56.346488Z"},"papermill":{"duration":2.499314,"end_time":"2022-10-14T16:18:37.278066","exception":false,"start_time":"2022-10-14T16:18:34.778752","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import warnings\n","import math\n","import random\n","import sqlite3\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import wandb\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    BertConfig,\n","    BertForSequenceClassification,\n","    DebertaConfig,\n","    DebertaForSequenceClassification,\n","    DebertaV2Config,\n","    DebertaV2ForSequenceClassification,\n","    get_cosine_schedule_with_warmup,\n",")\n","\n","seed = 42\n","random.seed(seed)\n","os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006923,"end_time":"2022-10-14T16:18:37.293015","exception":false,"start_time":"2022-10-14T16:18:37.286092","status":"completed"},"tags":[]},"source":["# Hyperparamters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:01.465067Z","iopub.status.busy":"2023-07-10T06:23:01.463878Z","iopub.status.idle":"2023-07-10T06:23:01.508233Z","shell.execute_reply":"2023-07-10T06:23:01.507234Z","shell.execute_reply.started":"2023-07-10T06:23:01.465030Z"},"papermill":{"duration":0.076785,"end_time":"2022-10-14T16:18:37.376836","exception":false,"start_time":"2022-10-14T16:18:37.300051","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["file_path = \"/data-new/yangzihao/DDI/\"\n","# file_path= '/kaggle/input/ddidatasets'\n","# file_path = \"./\"\n","\n","feature_list = [\"smile\", \"target\", \"enzyme\"]\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","cfg = {\n","    \"model_name\": \"bert-base-cased\",\n","    # \"model_name\": \"microsoft/deberta-v3-base\",\n","    \"epo_num\": 5,\n","    \"lr\": 5e-5,\n","    \"patience\": 0,  # 0 represent no early stop\n","    \"batch_size\": 16,\n","    \"max_len\": 256,\n","    \"use_amp\": False,   # Cause gradient underflow -> NaN\n","    \"forzen\": False,\n","}"]},{"cell_type":"markdown","metadata":{"id":"m425KHhNeKfD","papermill":{"duration":0.006757,"end_time":"2022-10-14T16:18:37.390736","exception":false,"start_time":"2022-10-14T16:18:37.383979","status":"completed"},"tags":[]},"source":["### Early stopping"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:01.510242Z","iopub.status.busy":"2023-07-10T06:23:01.509565Z","iopub.status.idle":"2023-07-10T06:23:01.538454Z","shell.execute_reply":"2023-07-10T06:23:01.537224Z","shell.execute_reply.started":"2023-07-10T06:23:01.510193Z"},"id":"W3tUeTSteKfD","jupyter":{"source_hidden":true},"papermill":{"duration":0.020304,"end_time":"2022-10-14T16:18:37.419280","exception":false,"start_time":"2022-10-14T16:18:37.398976","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path=None):\n","        # print(\"val_loss={}\".format(val_loss))\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            # self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            # print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            # self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\")\n","        torch.save(model.state_dict(), path + \"/\" + \"model_checkpoint.pth\")\n","        self.val_loss_min = val_loss"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006929,"end_time":"2022-10-14T16:18:37.493037","exception":false,"start_time":"2022-10-14T16:18:37.486108","status":"completed"},"tags":[]},"source":["# Data"]},{"cell_type":"markdown","metadata":{},"source":["#### Dataset_big"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:01.571067Z","iopub.status.busy":"2023-07-10T06:23:01.570722Z","iopub.status.idle":"2023-07-10T06:23:01.898430Z","shell.execute_reply":"2023-07-10T06:23:01.897513Z","shell.execute_reply.started":"2023-07-10T06:23:01.571036Z"},"trusted":true},"outputs":[],"source":["events = pd.read_csv(f'{file_path}/fusion_data/events.csv', index_col=0)\n","df_drug = pd.read_csv(f'{file_path}/fusion_data/drugs.csv', index_col=0)\n","# events = pd.read_csv(f'{file_path}/events.csv', index_col=0)\n","# df_drug = pd.read_csv(f'{file_path}/drugs.csv', index_col=0)\n","\n","# events.mechanism = events.mechanism + \" \" + events.action\n","# counts = events.mechanism.value_counts()\n","\n","# events['label'] = LabelEncoder().fit_transform(events.mechanism)\n","# events = events.drop(['index'], axis=1)\n","# df_drug = df_drug.drop(['id', 'index'], axis=1)\n","# df_drug = df_drug.set_index('name')\n","\n","# events.shape, df_drug.shape\n","display(events.head(1))\n","display(df_drug.head(1))"]},{"cell_type":"markdown","metadata":{},"source":["#### Dataset_small"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:02.744361Z","iopub.status.busy":"2023-07-10T06:23:02.743300Z","iopub.status.idle":"2023-07-10T06:23:02.753695Z","shell.execute_reply":"2023-07-10T06:23:02.750803Z","shell.execute_reply.started":"2023-07-10T06:23:02.744269Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.152105,"end_time":"2022-10-14T16:18:37.652127","exception":false,"start_time":"2022-10-14T16:18:37.500022","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# conn = sqlite3.connect(f\"{file_path}/fusion_data/event.db\")\n","# df_drug = pd.read_sql(\"select * from drug;\", conn)\n","# extraction = pd.read_sql(\"select * from extraction;\", conn)\n","# mechanism = extraction[\"mechanism\"]\n","# action = extraction[\"action\"]\n","# drugA = extraction[\"drugA\"]\n","# drugB = extraction[\"drugB\"]"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00686,"end_time":"2022-10-14T16:18:37.666693","exception":false,"start_time":"2022-10-14T16:18:37.659833","status":"completed"},"tags":[]},"source":["# Preprocess"]},{"cell_type":"markdown","metadata":{},"source":["sampling classes equally"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # 统计不同类别的数量\n","# label_counts = events[\"label\"].value_counts()\n","\n","# # 找到数量最少的类别\n","# min_label = label_counts.idxmin()\n","# min_count = label_counts.min()\n","\n","# # 对每个类别按最小数量采样\n","# sample_data = pd.concat(\n","#     [\n","#         resample(\n","#             events[events[\"label\"] == i],\n","#             n_samples=min_count,\n","#             replace=False,\n","#         )\n","#         for i in events[\"label\"].unique()\n","#     ]\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:02.760488Z","iopub.status.busy":"2023-07-10T06:23:02.758058Z","iopub.status.idle":"2023-07-10T06:23:02.782025Z","shell.execute_reply":"2023-07-10T06:23:02.780635Z","shell.execute_reply.started":"2023-07-10T06:23:02.760412Z"},"trusted":true},"outputs":[],"source":["class DDI_Dataset(Dataset):\n","    def __init__(self, ev_df, drug_df, tokenizer, max_len=256):\n","        self.events = ev_df\n","        self.drugs = drug_df\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return self.events.shape[0]\n","\n","    def __getitem__(self, index):\n","        d_a, d_b, labels = self.events.iloc[index]\n","        # d_a_seq = d_a + \",\" + ','.join(self.drugs.loc[d_a].values)\n","        # d_b_seq = d_b + \",\" + ','.join(self.drugs.loc[d_b].values)\n","        \n","        # use different modal\n","        # d_a_seq = d_a + f\", the drug {d_a}'s chemical form is: \" + self.drugs.loc[d_a].target\n","        # d_b_seq = d_b + f\", the drug {d_b}'s chemical form is: \" + self.drugs.loc[d_b].target\n","        # text = f'{d_a_seq + \" \" + self.tokenizer.sep_token + \" \" + d_b_seq}'\n","\n","        # use prompt\n","        text = f\"The drug {d_a} interacts with the drug {d_b}. \\\n","            The drug {d_a}'s information is: {','.join(self.drugs.loc[d_a].values)}. \\\n","            The drug {d_b}'s information is: {','.join(self.drugs.loc[d_b].values)}.\"\n","        \n","        # print(text)\n","\n","        encode_dict = self.tokenizer.encode_plus(\n","            text=text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            truncation=True,\n","            padding=\"max_length\",\n","            return_attention_mask=True,\n","            return_tensors=\"pt\",\n","        )\n","        ids = encode_dict[\"input_ids\"].squeeze(0)\n","        masks = encode_dict[\"attention_mask\"].squeeze(0)\n","        \n","        return {\"ids\": ids, \"masks\": masks, \"labels\": labels}"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007085,"end_time":"2022-10-14T16:18:47.067096","exception":false,"start_time":"2022-10-14T16:18:47.060011","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:53.685490Z","iopub.status.busy":"2023-07-10T06:23:53.684888Z","iopub.status.idle":"2023-07-10T06:23:57.380751Z","shell.execute_reply":"2023-07-10T06:23:57.379828Z","shell.execute_reply.started":"2023-07-10T06:23:53.685450Z"},"trusted":true},"outputs":[],"source":["model_name = cfg['model_name']\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=100)\n","\n","\n","# scratch bert\n","# config = BertConfig()\n","# model = BertForSequenceClassification(config)\n","\n","# scratch debertaV3\n","# config = DebertaV2Config.from_pretrained('microsoft/deberta-v3-base')\n","# config.num_labels = 100\n","# model = DebertaV2ForSequenceClassification(config)\n","# model.init_weights()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, num_classes, alpha=0.25, gamma=2):\n","        super(FocalLoss, self).__init__()\n","        self.num_classes = num_classes\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, logits, targets):\n","        probs = F.softmax(logits, dim=1)\n","        targets_one_hot = F.one_hot(targets, num_classes=self.num_classes)\n","        pt = torch.sum(probs * targets_one_hot, dim=1) + 1e-6\n","        focal_loss = -self.alpha * (1 - pt) ** self.gamma * torch.log(pt)\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007079,"end_time":"2022-10-14T16:18:47.275069","exception":false,"start_time":"2022-10-14T16:18:47.267990","status":"completed"},"tags":[]},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb_key = \"69d3c1285c2d5121bb31b7fd541ff6b576817ead\"\n","wandb.login(key=wandb_key)\n","\n","run = wandb.init(\n","    project=\"DDI\",\n","    config=cfg,\n","    dir=f\"{file_path}\",\n","    name=\"bert-pretrained\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:57.411238Z","iopub.status.busy":"2023-07-10T06:23:57.410885Z","iopub.status.idle":"2023-07-10T06:23:57.428581Z","shell.execute_reply":"2023-07-10T06:23:57.427617Z","shell.execute_reply.started":"2023-07-10T06:23:57.411204Z"},"trusted":true},"outputs":[],"source":["# Training configuration\n","\n","# sample half of the data for test\n","# experiment_data = events.sample(int(events.shape[0] * 0.5))\n","experiment_data = events\n","total_train, total_valid = train_test_split(\n","    experiment_data, test_size=0.2, random_state=42\n",")\n","print(f\"All data size: {experiment_data.shape[0]}\")\n","print(f\"train size: {total_train.shape[0]}, test size: {total_valid.shape[0]}\")\n","\n","train_dataset = DDI_Dataset(total_train, df_drug, tokenizer, max_len=cfg[\"max_len\"])\n","train_loader = DataLoader(train_dataset, batch_size=cfg[\"batch_size\"], shuffle=True)\n","valid_dataset = DDI_Dataset(total_valid, df_drug, tokenizer, max_len=cfg[\"max_len\"])\n","valid_loader = DataLoader(valid_dataset, batch_size=cfg[\"batch_size\"], shuffle=True)\n","\n","optimizer = optim.AdamW(model.parameters(), lr=cfg[\"lr\"], eps=1e-3)\n","scaler = torch.cuda.amp.GradScaler(enabled=cfg[\"use_amp\"])\n","if cfg[\"use_amp\"]:\n","    print(\"Using AMP!\")\n","\n","if cfg['forzen']:\n","    print(\"Freeze the base model!\")\n","    for param in model.base_model.parameters():\n","        param.requires_grad = False\n","\n","num_training_steps = cfg[\"epo_num\"] * len(train_loader)\n","num_warmup_steps = int(0.3 * num_training_steps)\n","lr_scheduler = get_cosine_schedule_with_warmup(\n","    optimizer=optimizer,\n","    num_warmup_steps=num_warmup_steps,\n","    num_training_steps=num_training_steps,\n",")\n","\n","criterion = FocalLoss(num_classes=100)\n","# criterion = nn.CrossEntropyLoss()\n","\n","\n","def accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten().numpy()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-10T06:23:57.431957Z","iopub.status.busy":"2023-07-10T06:23:57.431267Z"},"trusted":true},"outputs":[],"source":["# Start training\n","\n","for i in range(cfg[\"epo_num\"]):\n","    print(\"Epoch {}/{}\".format(i + 1, cfg[\"epo_num\"]))\n","    print(\"-\" * 10)\n","\n","    train_epoch_loss = []\n","    train_epoch_acc = []\n","    valid_epoch_loss = []\n","    valid_epoch_acc = []\n","    # early_stopping = EarlyStopping(patience=cfg[\"patience\"], verbose=True)\n","\n","    model.to(device)\n","    model.train()\n","    for step, batch in tqdm(\n","        enumerate(train_loader), total=len(train_loader), desc=\"Train\"\n","    ):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        ids, masks, labels = batch[\"ids\"], batch[\"masks\"], batch[\"labels\"]\n","\n","        with torch.autocast(\n","            device_type=\"cuda\", dtype=torch.float16, enabled=cfg[\"use_amp\"]\n","        ):\n","            outputs = model(ids, masks)\n","            logits = outputs.logits\n","            loss = criterion(logits, labels)\n","\n","        train_acc = accuracy(logits.detach().cpu().numpy(), labels.cpu())\n","        train_epoch_acc.append(train_acc)\n","        train_epoch_loss.append(loss.item())\n","\n","        if step % 200 == 0:\n","            wandb.log({\"train_acc\": train_acc,\"train_loss\": loss.item()})\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        lr_scheduler.step()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        # early_stopping(loss.item(), model)\n","        # if early_stopping.early_stop:\n","        #     print(\"Early stopping\")\n","        #     break\n","\n","    # Evaluate after every epoch.\n","    model.eval()\n","    with torch.no_grad():\n","        for step, b in tqdm(\n","            enumerate(valid_loader), total=len(valid_loader), desc=\"Valid\"\n","        ):\n","            b = {k: v.to(device) for k, v in b.items()}\n","            ids, masks, labels = b[\"ids\"], b[\"masks\"], b[\"labels\"]\n","\n","            outputs = model(ids, masks)\n","            logits = outputs.logits\n","            loss = criterion(logits, labels)\n","\n","            valid_acc = accuracy(logits.detach().cpu().numpy(), labels.cpu())\n","            valid_epoch_acc.append(valid_acc)\n","            valid_epoch_loss.append(loss.item())\n","\n","            if step % 200 == 0:\n","                wandb.log({\"valid_acc\": valid_acc, \"valid_loss\": loss.item()})\n","\n","    avg_train_loss = sum(train_epoch_loss) / len(train_epoch_loss)\n","    avg_train_acc = sum(train_epoch_acc) / len(train_epoch_acc)\n","    avg_valid_loss = sum(valid_epoch_loss) / len(valid_epoch_loss)\n","    avg_valid_acc = sum(valid_epoch_acc) / len(valid_epoch_acc)\n","\n","    print(\"Training Loss: {:.4f}\".format(avg_train_loss))\n","    print(\"Training Acc: {:.4f}\".format(avg_train_acc))\n","    print(\"Valid Loss: {:.4f}\".format(avg_valid_loss))\n","    print(\"Valid Acc: {:.4f}\".format(avg_valid_acc))\n","    print()\n","\n","print()\n","print(\"Training complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_save_directory = f\"{file_path}/saved_models/{cfg['model_name']}-pretrained\"\n","tokenizer.save_pretrained(model_save_directory)\n","model.save_pretrained(model_save_directory)\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"paddle_env","language":"python","name":"paddle_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":4}
